## 算法是什么?

非形式化地说, 算法(algorithm)就是任何经过良好定义的计算过程, 这个过程取某个值或值的集合作为输入并在有限的时间内产生某个值或值的集合作为输出. 这样算法就是把输入转换成输出的计算步骤的一个序列.

**快速排序作为算法的一个例子**

![[快速排序作为算法的例子.excalidraw]]

**编译器作为算法的一个例子**

![[编译器作为算法的例子.excalidraw]]

**GPT模型作为算法的一个例子**

![[GPT模型作为算法的例子.excalidraw]]

## 算法需要满足的条件

- 在合理的时间内运行结束. 一个排序执行1年不太合适.
- 不能占用太大的空间, 一个排序占用1T内存不太合适.

## 为什么要学习算法?

- 计算机科学所有分支学科的核心都是算法
- 顶尖工程师一定精通算法
- 学好算法是成为一名优秀的工程师的必要条件

## 一些应用场景举例

- 操作系统内核:
  - 各种链表的使用
  - 红黑树(epoll)
  - 环形缓冲区
  - ...
- 编译器
  - 有限状态机
  - 树(抽象语法树)
  - 图论(寄存器分配)
  - 垃圾收集(深度优先搜索)
  - ...
- 数据库
  - B+树(MySQL索引)
  - 图论(执行计划的优化)
  - 树形结构(抽象语法树)
  - ...
- TCP-IP协议
  - 有限状态机(三次握手的流程)
  - 滑窗算法(流量控制和乱序重排)
  - ...
- 分布式系统
  - Paxos算法(zookeeper, etcd, ...)
  - 工作量证明(比特币)
  - ...
- GPT模型
  - 反向传播算法(动态规划+链式求导)
  - 多层感知机
  - Transformer模型
  - ...

## 程序的性能分析

- 时间复杂度: 主要分析一个程序需要执行多长时间
- 空间复杂度: 主要分析一个程序需要使用多少内存

> 程序执行多长时间说的更加精确一些应该是: 需要多少个**时间单位**
>
> 程序的空间复杂度, 我们一般分析内存的占用情况, 磁盘之类的外存一般不考虑

## 为什么要分析程序的性能?

- CPU可能很快, 但不是无限快
- 内存和磁盘可能很便宜, 但并不是无限大和不要钱的
- 解决同样的问题, 一个好的算法比一个不好的算法需要的时间少得多

> 例如: 一个已经排序好的包含1亿个元素的数组, 要查找1个元素是否在数组中, 使用线性查找算法(也就是从头到尾遍历数组去查找这个元素), 如果碰到最坏的情况(待查找元素不在数组中), 那么需要花费1亿个时间单位才能发现元素不在数组中. 如果使用二分查找算法, 那么碰到最坏的情况, 只需要$\log_2(1,0000,0000)\approx 27$次就可以得出元素不在数组中的结论.

## 程序性能是基于什么样的计算机模型来说的?

- 肯定**不能**是量子计算机模型.
- 我们使用简单的通行的冯诺依曼-图灵架构.

## 我们选用的冯诺依曼架构的特点

- 单核(只有1个CPU)
- CPU的指令一条接着一条的按顺序执行(不存在并行执行)
- CPU的指令集只包含简单的指令
  - 算术指令: 加法, 减法, 乘法, 除法, 取余, 向下取整, 向上取整
  - 数据移动指令: 加载, 存储, 复制
  - 控制指令: 条件与无条件转移, 子程序调用与返回
  - 每条这样的指令所需时间都为常量(一个时间单位)
  - 没有排序指令, 矩阵相乘指令这样的神奇指令
- 内存是随机存取器(Random Access Memory, RAM)
- 内存是一个巨大的字节数组
- 使用索引读写内存中的某个字节例如: `a[1] = 1;`, 花费常量时间(1个时间单位)

假设我们的CPU是8位的, 那么寻址空间(也就是索引字节数组的大小)是$0\sim 255$, 也就是一个进程所能使用的最大内存空间是$255$个字节. 换成十六进制表示则是$0x00 \sim 0xFF$. 如下图所示:

![[内存模型示意图.excalidraw]]

## 时间复杂度

我们一般假设一段程序的时间复杂度(运行时间)是$T(N)$, $N$表示程序的输入规模(例如数组的大小, 大整数的位数等等). 那么$T(N)$一般求得的结果我们使用**大$O$表示法**来表示. 我们通过举例子的方式来看一下大$O$表示法是什么东西.

> 大$O$表示法是最常用的, 时间复杂度的分析其实涉及比较深的数学知识, 有大$O$表示法, 大$\Theta$表示法, 大$\Omega$表示法等等. 但这里为了方便理解, 我们只讲大$O$表示法, 并将它通俗化.

**常数时间**$O(1)$

> 表示只使用1个时间单位.

```java
int f() {
    return 1; // O(1)
}
```

假设方法`f`的时间复杂度是$T$, 由于`return 1`返回语句只需要1个时间单位, 所以`f`的时间复杂度是$T=O(1)$.

```java
int f() {
    int a = 1; // O(1)
    return a;  // O(1)
}
```

两条语句的时间复杂度都是$O(1)$, 而$O(1) + O(1) = 2O(1) = O(1)$. 这个等式可能有些奇怪, 但没有问题. 因为大$O$表示法本身是时间复杂度的一个大概估计(精确分析非常困难且没有必要). 所以我们一般舍弃低阶项和常数系数. 例如: $O(2N) = O(N)$, $O(N)+O(N^2)=O(N^2)$等等.

列举一些常用的常数时间复杂度的代码:
- `int a = 1`: 赋值需要1个时间单位, 所以是$O(1)$.
- `i++`: 等价于`i = i + 1`, 加法操作需要$O(1)$, 赋值操作需要$O(1)$. 所以$O(1) + O(1) = 2O(1) = O(1)$. 这里忽略了系数.
- `i > j`: 比较操作需要$O(1)$.
- `return a + b`: 加法操作需要$O(1)$, `return`需要$O(1)$, 所以这个`return`语句是$O(1)$.

**线性时间**$O(N)$

> 表示使用$N$个时间单位

```java
1  int search(int[] nums, int target) {
2      int N = nums.length;
3      for (int i = 0; i < N; i++) {
4          if (nums[i] == target) return i;
5      }
6      return -1;
7  }
```

假设方法`search`的时间复杂度是$T(N)$, 我们分析最坏情况, 也就是`target`不在数组中的情形, 我们逐行分析:
- 第2行: 获取数组长度需要$O(1)$, 赋值需要$O(1)$, 两者相加, 时间复杂度是$O(1)$.
- 第3行: `for`循环的括号中的3个语句(每个语句执行一次时间复杂度都是$O(1)$), 我们分别来看一下时间复杂度是多少. `int i = 0`只执行1次, 时间复杂度是$O(1)$. `i < N`执行了$N+1$次. `i++`执行了$N$次. 所以时间复杂度是: $O(1) + (N+1)\cdot O(1) + N\cdot O(1) = O(2N + 2) = O(N)$.
- 第4行: 由于是最坏情况, 所以每轮循环执行一次条件检测`nums[i] = target`, 时间复杂度是$O(1)$. 一共执行了$N$轮循环. 所以时间复杂度是$N\cdot O(1)=O(N)$.
- 第6行: 时间复杂度是$O(1)$.

把每一行代码所用的时间加起来得到
$$
\begin{equation*}
\begin{aligned}
T(N) &= O(1) + O(N) + O(N) + O(1) \\
     &= O(2N + 2) \\
     &= O(N)
\end{aligned}
\end{equation*}
$$
所以方法`search`的时间复杂度是$O(N)$, 也就是线性时间复杂度.

**平方时间**$O(N^2)$

```java
void f(int N) {
    for (int i = 0; i < N; i++) {     // O(N)
        for (int j = 0; j < N; j++) { // O(N^2)
            System.out.println("hello world");// O(N^2)
        }
    }
}
```

这段代码的时间复杂度如何计算?
$$
\begin{aligned}
T(N) &= O(1) + O(N^2) + O(N^2) \\
     &= O(2N^2 + 1) \\
     &= O(N^2)
\end{aligned}
$$
**对数时间**$O(\log{N})$

这里的符号$\log{N}$实际上是$\log_2N$. 因为在计算机中, 不明确说明对数都是**以2为底**的.

通常情况下, 当我们将一个问题分割为**完全不重合**的子问题时, 时间复杂度就会出现对数时间.

我们举个**递归实现的二分查找**的例子.

> 二分查找要解决的问题是在已经升序排列的数组中寻找某个特定元素的问题.

```java
 1  int search(int[] A, int t, int L, int R) {
 2      if (L <= R) {                          // O(1)
 3          int M = (L + R) / 2;               // O(1)
 4          if (A[M] == t) {                   // O(1)
 5              return M;                      // O(1)
 6          } else if (A[M] < t) {             // O(1)
 7              return search(A, t, M + 1, R); // T(N/2)
 8          } else {
 9              return search(A, t, L, M - 1); // T(N/2)
10          }
11      }
12    
13      return -1;                             // O(1)
14  }
```

上面是递归实现的二分查找算法. 我们来考虑最坏情况下的时间复杂度, 而最坏情况就是要查找的元素`t`不在数组`A`里面.

> [!note]
> 我们一般分析的是 **最坏情况** 的时间复杂度, 因为最好情况一般来说没什么意义. 例如二分查找的最好情况是要查找的元素正好位于正中间, 那么第一次循环就找到了. 时间复杂度是 $O(1)$ .

我们假设上面方法的时间复杂度是 $T(N)$ . $N$ 是 `A` 数组的长度. 由于方法体中的递归调用针对的是砍掉一半的数组, 所以第7行和第9行的时间复杂度分别是$T(N/2)$. 而第7行和第9行的递归调用每次只会调用其中一个. 所以时间复杂度的推导公式可以得到
$$
\begin{aligned}
T(1) &= O(1) \\
T(N) &= T(N/2) + O(1)
\end{aligned}
$$
为了方便推导, 我们假设$N=2^M$. 我们先来复习一下替换法则, 根据上面的公式可以得到
$$
T(N/2) = T(N/4) + O(1)
$$
$$
T(N/4) = T(N/8) + O(1)
$$

我们开始推导
$$
\begin{equation*}
\begin{aligned}
T(N) &= T(\frac{N}{2}) + O(1) \\
     &= T(\frac{N}{2^2}) + 2O(1) \\
     &= T(\frac{N}{2^3}) + 3O(1) \\
     &= \cdots \\
     &= T(\frac{N}{2^M}) + MO(1) \\
     &= T(1) + MO(1) \\
     &= (M+1)O(1) \\
     &= MO(1) \\
     &= O(M) \\
     &= O(\log N)
\end{aligned}
\end{equation*}
$$
上面公式要注意的是: $T(1) = O(1)$. 为什么呢? 因为如果数组只有1个元素, 那么我们只需要$O(1)$的时间就可以确定待查找元素是否在数组中. 还要注意的一点是: $MO(1)=O(M)$. 这个很好理解.

**线性对数时间**$O(N\log N)$

我们以归并排序为例, 归并排序的思路是先将数组**分解**成两个子数组, 然后对两个子数组分别进行归并排序, 两个子数组都排好序之后, 将两个排好序的子数组**合并**成排好序的完整数组.

> [!note]
> 归并排序实际上使用的是"分治"思想, 我们会在排序部分详细讲解归并排序. 并研究一下分治算法的设计思路, 这里只是计算时间复杂度.

```java
// 这里我们不给出Merge(合并)操作的具体代码,
// 只需要知道Merge的时间复杂度是O(N)就可以了.
void Merge(int[] array, int left, int mid, int right) {
    // ...
}

// 归并排序的主程序, 时间复杂度设为T(N)
void MergeSort(int[] array, int left, int right) {
    if (left <= right) {                   // O(1)
        int mid = (left + right) / 2;      // O(1)
        MergeSort(array, left, mid);       // T(N/2)
        MergeSort(array, mid+1, right);    // T(N/2)
        Merge(array, left, , mid, right);  // O(N)
    }
}
```

将归并排序的主程序的每一行的时间复杂度都加起来, 可得
$$
T(N) = 2T(N/2) + O(N)
$$
我们还是假设$N=2^M$. 推导过程如下
$$
\begin{equation*}
\begin{aligned}
T(N) &= 2T(N/2) + O(N) \\
     &= 2(2T(N/4) + O(N/2)) + O(N) \\
     &= 4T(N/4) + 2O(N) \\
     &= 8T(N/8) + 3O(N) \\
     &= 2^3T(\frac{N}{2^3}) + 3O(N) \\
     &= \cdots \\
     &= 2^MT(\frac{N}{2^M}) + MO(N) \\
     &= NT(1) + \log NO(N) \\
     &= (\log N + 1)O(N) \\
     &= \log N\cdot O(N) \\
     &= O(N\log N)
\end{aligned}
\end{equation*}
$$
**指数时间**$O(2^N)$

斐波那契数列的通项公式如下
$$
Fib(N)=
\begin{cases}
0\quad &如果N=0 \\
1\quad &如果N=1 \\
Fib(N-1) + Fib(N-2)\quad &如果N\geq 2
\end{cases}
$$
转换成代码如下

```java
long Fib(int N) { // T(N)
    if (N == 0 || N == 1) {
        return N; // O(1)
    } else {
        return Fib(N-1) + Fib(N-2); // T(N-1)+T(N-2)+O(1)
    }
}
```

而时间复杂度的分析和通项公式是一致的. 假设调用`Fib(N)`的时间复杂度是$T(N)$. 则递归调用`Fib(N-1)`的时间复杂度是$T(N-1)$, 同理`Fib(N-2)`的时间复杂度是$T(N-2)$. 于是有如下
$$
\begin{equation*}
\begin{aligned}
T(0) &= O(1) \\
T(1) &= O(1) \\
T(N) &= T(N-1) + T(N-2) + O(1)
\end{aligned}
\end{equation*}
$$
上面的式子看起来很难推导. 我们这里使用数学归纳法来解决这个问题. 首先我们的 **归纳假设** 是 $T(N-1)=O(2^{N-1})$ , 然后需要证明 $T(N)=O(2^N)$ . 对于$T(0)和T(1)$显然是成立的(**基准情况**). 那么递推公式就变成了
$$
\begin{aligned}
T(N) &= O(2^{N-1}) + O(2^{N-2}) + O(1) \\
     &= O(\frac{3}{4}\cdot 2^N) + O(1) \\
     &= O(2^N)
\end{aligned}
$$
这样我们就证明了$T(N)=O(2^N)$. 可以看出程序的运行时间是指数时间.

## 空间复杂度

我们所说的空间复杂度实际上是指一个程序在运行期间会占用多少空间资源(内存, 磁盘). 但在算法分析中, 我们一般关心的是一个算法在运行时会占用多少**内存**.

我们来举几个例子

```java
int a = 1; 
```

不管使用多少个局部变量, 我们一般认为局部变量使用的空间是$O(1)$.

```java
void f(int N) {
    int[] array = new int[N];
}
```

我们开辟了一个大小为$N$的数组, 所以空间复杂度是$O(N)$.

在函数调用时, 会使用内存来作为**栈帧**的空间. 在分析算法时, 最常见到的是递归调用时所使用的栈帧内存空间.

我们来写一段计算**斐波那契数列**的代码. 斐波那契数列的定义如下:
$$
\begin{aligned}
Fib(0) &= 0 \\
Fib(1) &= 1 \\
Fib(N) &= Fib(N-1) + Fib(N-2)
\end{aligned}
$$
代码如下:

```java
int fib(int N) {
    if (N == 0 || N == 1) return N;
    else return fib(N-1) + fib(N-2);
}
```

> [!note]
> 后面我们会详细讲解斐波那契数列. 这个东西很重要.

以计算`fib(3)`为例. 内存布局如下:

![[斐波那契数列的内存布局.excalidraw|1000]]

每个栈帧空间按照空间复杂度$O(1)$来算. 如果$N$比较大的话, 由于存在海量的重复调用, 所以空间复杂度是指数级别. 所以很容易就`StackOverflow`(爆栈)了.

## 算法的正确性

我们上面讲了如何粗糙地分析一个算法的性能. 现在我们来讲一下算法的正确性. 也就是说, 我们设计一个算法出来之后, 如何知道这个算法是否正确? 现在最常用的方式是**测试**, 也就是通过输入几个测试用例看看输出是否正确. 但这种方式只能说明对输入的测试用例, 算法的工作没有问题. 并不能说明对于所有的输入算法都能正确运行. 因为测试用例只能尽可能的覆盖输入, 而无法全部覆盖.

所以一些很关键的算法, 可能就需要使用形式化的方法来证明这个算法的正确性了. 这里我们使用的形式化方法叫做**循环不变量**(loop invariant).

### 常用证明手段

#### 数学归纳法

数学归纳法的思路是先对 ==**基准条件**== 证明定理为真, 再对 **归纳假设** 证明定理为真即可.

**定理**: 对所有的$n\in \mathbb{N}$,
$$
\sum_{i=1}^ni = 1 + 2 + 3 + \cdots + n = \frac{n(n+1)}{2}
$$
**证明**:

- **基准条件**. 对于$n=1$时, 公式显然成立.
- **归纳假设**. 假设对于$n$公式成立, 需要证明公式对$n+1$成立.

$$
\begin{aligned}
\sum_{i=1}^{n+1}i &= 1 + 2 + 3 + \cdots + n + (n + 1) \\
                  &= \frac{n(n+1)}{2} + (n+1) \\
                  &= \frac{(n+1)(n+2)}{2}
\end{aligned}
$$

定理得证.

#### 反证法

反证法的思路是先假设定理不成立, 然后证明假设是错误的.

**定理**: $\sqrt{2}$是无理数.

**证明**: 首先我们知道 **任何有理数都可以表示为两个整数的商**. 假设$\sqrt{2}$是有理数. 我们可以将$\sqrt 2$最简分数形式(分子分母没有公约数), 即$\sqrt 2 = n/d$, $n$和$d$是整数且没有公约数. 两边同时平方, 得到$2=n^2/d^2 \to 2d^2=n^2$. 所以可以知道$n$是$2$的倍数. 所以$n^2$一定是$4$的倍数. 所以$2d^2$一定是$4$的倍数. 那么$d^2$一定是$2$的倍数. 那么$d$一定是$2$的倍数. $d$和$n$都有约数$2$, 和假设矛盾. 所以定理得证.

### 循环不变量

循环**不变量**是在每个循环迭代的开始和结束时为真的条件, 当我们编写一个可以正常工作的循环时, 至少隐含地依赖了一个循环不变量. 了解什么是循环不变量并明确地思考循环不变量将帮助我们编写正确且高效的代码来实现棘手的算法.

我们以**迭代实现的二分查找**为例子来看一下, 为了方便讲解, 我们的**前置条件**保证要寻找的`target`一定在数组`array`中. 我们这个二分查找有以下几个前置条件:
- 数组升序排列.
- 数组中的元素都不一样.
- 寻找的目标`target`一定在数组`array`中.

```java
int IterativeBinarySearch(int[] array, int target) {
    int left = 0;
    int right = array.length - 1;
    while (left <= right) {
        int mid = (left + right) / 2;
        if (target > array[mid]) {
            left = mid + 1;
        } else if (target < array[mid]) {
            right = mid - 1;
        } else if (target == array[mid]) {
            assert(left <= right);
            return mid;
        }
        assert(left <= right);
    }
    return -1;
}
```

> [!note]
> `return -1`表示未找到, 这里为了保证语法正确. 因为我们已经知道`target`一定在`array`中.

从概念上讲, 这个算法很简单. 但是要完全正确编写代码是很棘手的. 我们怎么知道我们得到了正确的计算`mid`? 为什么是`target < array[mid]`? 为什么`left = mid + 1`以及`right = mid -1`? 如果我们改变这些决定中的任何一个, 算法都可能无法找到正确的元素.

为了说服我们自己编写的是正确的代码, 我们需要一个包含三个子句的循环不变量:

>[!note]
>找到一个循环的循环不变量是一件不太容易的事情!

1. $array$是升序排列.
2. $left \leq right$.
3. $target \in array[left..right]$.

如果我们知道一个循环的循环不变量, 作为文档记录下来是个好主意. 我们甚至可以以加断言`assert`的方式来作为文档. 也就是在每次循环执行时执行断言. 我在代码里就添加了一些断言.

**使用循环不变量来证明代码是正确的**

循环不变量可以帮助我们说服自己, 我们的代码, 尤其是棘手的代码, 是正确的. 它们可以帮助我们开发出正确的代码, 帮助我们编写高效的代码.

要使用循环不变量来论证代码执行我们想要的操作, 我们使用以下步骤:

1. **初始化**. 循环的第一次迭代之前, 循环不变量为真.
2. **保持**. 证明如果假设了循环的某次迭代之前循环不变量为真, 那么下次迭代之前循环不变量仍为真.
3. **终止**. 在循环终止时, 循环不变量为我们提供一个有用的性质. 这个性质有助于证明算法是正确的.

> 这个过程类似数学归纳法. 初始化是基准条件, 保持是归纳假设, 终止要说明我们这个循环一定会结束, 不是死循环.

让我们在二分查找算法上尝试这三个步骤.

1. **初始化**. 首先证明在第一次循环迭代之前, 循环不变量成立. 循环不变量包含三个部分:

   1. 数组升序排序, 这是我们的前置条件所保证的.
   2. 由于$array.length$至少为1, 因此$left\leq right$.
   3. $target$在$array[left..right]$中, 因为那是整个数组, 我们的前置条件保证$target$在数组里面.

   这表明在第一次循环迭代之前循环不变量成立.

2. **保持**. 由于我们代码中没有对数组做任何更改, 所以循环不变量(1)一直成立. 我们主要看循环不变量(2)和循环不变量(3)的证明. 我们先来看循环不变量(2): $left\le right$. 如果某一轮循环执行之前, 有$left\le right$成立, 我们需要证明这轮循环结束时, 也成立. 也就是第11行和第13行代码的断言成立. 由于前置条件保证了$target\in array[left..right]$, 所以一定只有以下三种情况:

   1. $target\in array[left..mid-1]$. 如果落到这个情况, 也就是第8行的条件为真, 那么本轮循环结束时, 有$left$不变, $right=mid-1$. 显然有$left<=mid-1=right$.
   2. $target\in array[mid+1..right]$. 分析同上.
   3. $target==array[mid]$. 此时直接退出循环, $left$和$right$都没变. 所以也成立.

   而且可以看到, 对于以上三种情况, 循环不变量(3)在每轮循环结束也是成立的.

3. **终止**. 我们的算法一定会终止吗? 这一点非常重要. 如果某一轮循环中有$target==array[mid]$成立, 那么我们找到了元素, 且直接`return`. 这种情况下循环就终止了. 而在没找到目标之前的每轮循环中, 要么$left=mid+1$, 要么$right=mid-1$. 也就是搜索数组的范围一直在缩小. 最坏情况下, 会一直缩小到搜索范围中只有一个元素, 也就是$left=right$的情况. 而由于我们的前置条件保证了目标一定在数组中, 所以这个元素就是目标. 而根据保持阶段的论证, 最后一轮循环结束时, 循环不变量也是成立的.

至此迭代式二分查找算法的正确性得到了证明. 我们可以放心使用了.